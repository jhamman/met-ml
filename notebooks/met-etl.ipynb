{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ETL\n",
    "*Extract-transform-load*\n",
    "\n",
    "This notebook does the data engineering steps required for the Met-ML training and evaluation:\n",
    "\n",
    "- load fluxnet csvs\n",
    "- fit transformers on the full dataset\n",
    "- saves the preprocessed data and transformers for use in the next steps of the project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mamba install -y -c conda-forge python-snappy openpyxl intake-parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load_ext lab_black\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import intake\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "\n",
    "from tqdm import tqdm\n",
    "from joblib import dump\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import cartopy.crs as ccrs\n",
    "from dask.distributed import Client\n",
    "\n",
    "import fsspec\n",
    "\n",
    "\n",
    "from met_ml.data import cat\n",
    "from met_ml.train.fluxnet_etl import load_fluxnet, get_meta, make_lookback\n",
    "from met_ml.train.models import fit_transformers, transform_df\n",
    "\n",
    "\n",
    "SCRATCH = os.getenv('PANGEO_SCRATCH', 's3://pangeo-scratch/jhamman/')\n",
    "\n",
    "lookback = 90\n",
    "train_vars = [\"P\", \"t_min\", \"t_max\", \"t\", \"lat\", \"elev\"]\n",
    "target_vars = [\"SW_IN_F\", \"LW_IN_F\", \"PA_F\", \"RH\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = Client(n_workers=8)\n",
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: put this dataset in cat\n",
    "# also, there may be a new version of this...?\n",
    "\n",
    "all_site_meta = pd.read_excel(\"../met_ml/data/FLX_AA-Flx_BIF_LATEST.xlsx\").set_index(\n",
    "    [\"SITE_ID\", \"VARIABLE\"]\n",
    ")[\"DATAVALUE\"]\n",
    "\n",
    "all_site_meta.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = load_fluxnet(cat, all_site_meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_sites = all_site_meta.index.get_level_values(0).unique()\n",
    "meta = get_meta(all_site_meta)\n",
    "meta = pd.DataFrame.from_dict(meta, orient=\"index\")\n",
    "test_meta = meta.sort_values([\"lat\"])[::5]\n",
    "\n",
    "fig = plt.figure(figsize=(12, 8))\n",
    "ax = fig.add_subplot(1, 1, 1, projection=ccrs.Robinson())\n",
    "ax.scatter(meta.lon, meta.lat, transform=ccrs.PlateCarree(), label=\"Training Sites\")\n",
    "ax.scatter(\n",
    "    test_meta.lon,\n",
    "    test_meta.lat,\n",
    "    c=\"r\",\n",
    "    transform=ccrs.PlateCarree(),\n",
    "    label=\"Validation Sites\",\n",
    ")\n",
    "ax.set_global()\n",
    "ax.stock_img()\n",
    "ax.coastlines()\n",
    "ax.gridlines()\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta = meta.reindex(df.index.levels[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_by_meta(df, keys, test_keys):\n",
    "    train = []\n",
    "    val = []\n",
    "\n",
    "    for key in keys:\n",
    "        if key in test_keys:\n",
    "            val.append(df.loc[key])\n",
    "        else:\n",
    "            train.append(df.loc[key])\n",
    "    return train, val\n",
    "\n",
    "\n",
    "def qc(da):\n",
    "    if da.isnull().sum() > 0:\n",
    "        print(\"nans found\")\n",
    "\n",
    "\n",
    "# split the data into train/val groups\n",
    "# x_train, x_val, y_train, y_val = split(x_data_computed, y_data_computed)\n",
    "train, val = split_by_meta(df, meta.index.to_list(), test_meta.index.to_list())\n",
    "\n",
    "\n",
    "# fit the transformers\n",
    "trans = fit_transformers(train)\n",
    "# x_trans = subset_columntransformer(trans.transformers, trainl\n",
    "\n",
    "\n",
    "# create the 3D tensor for the LSTM including a lookback dimension\n",
    "for name, df_list in zip([\"train\", \"val\"], [train, val]):\n",
    "    da = xr.concat(\n",
    "        [make_lookback(transform_df(trans, d), lookback=lookback) for d in df_list],\n",
    "        dim=\"samples\",\n",
    "    )\n",
    "    da.name = name\n",
    "    print(name, da.shape)\n",
    "    # display(da)\n",
    "    qc(da)\n",
    "\n",
    "    # save x data\n",
    "    mapper = fsspec.get_mapper(f'{SCRATCH}/metml/etl/x_{name}.zarr')\n",
    "    da.to_dataset(name='x').sel(features=train_vars).chunk({'samples': 10000}).to_zarr(mapper, mode='w', consolidated=True)\n",
    "\n",
    "    # save y data\n",
    "    mapper = fsspec.get_mapper(f'{SCRATCH}/metml/etl/y_{name}.zarr')\n",
    "    da.to_dataset(name='y').sel(features=target_vars).isel(lookback=-1).chunk({'samples': 10000}).to_zarr(mapper, mode='w', consolidated=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_vars(df):\n",
    "    fig, axes = plt.subplots(\n",
    "        ncols=len(df.columns), nrows=1, sharex=True, figsize=(22, 4)\n",
    "    )\n",
    "\n",
    "    for ax, (key, s) in zip(axes, df.items()):\n",
    "        print(key)\n",
    "        s.plot(ax=ax)\n",
    "        ax.set_title(key)\n",
    "\n",
    "\n",
    "d = train[0]\n",
    "plot_vars(d[train_vars])\n",
    "plot_vars(d[target_vars])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "td = transform_df(trans, d)\n",
    "plot_vars(td[train_vars])\n",
    "plot_vars(td[target_vars])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: use ONNX for this\n",
    "with fsspec.open(f'{SCRATCH}/metml/etl/fluxnet_all_transformers.joblib', mode='wb') as f:\n",
    "    dump(trans, f)  # save for later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with fsspec.open(f'{SCRATCH}/metml/etl/fluxnet.csv', mode='w') as f:\n",
    "    df.to_csv(f)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with fsspec.open(f'{SCRATCH}/metml/etl/meta.csv', mode='w') as f:\n",
    "    meta.to_csv(f)\n",
    "meta.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with fsspec.open(f'{SCRATCH}/metml/etl/test_meta.csv', mode='w') as f:\n",
    "    test_meta.to_csv(f)\n",
    "test_meta.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:notebook] *",
   "language": "python",
   "name": "conda-env-notebook-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
